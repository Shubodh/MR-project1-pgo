{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Pose Graph Optimization (scratch + g2o)\n",
    "TEAM-ID:     \n",
    "TEAM-NAME:        \n",
    "YOUR-ID:      \n",
    "YOUR-NAME:     \n",
    "\n",
    "(Although you work in groups, both the students have to submit to Moodle, hence there's name field above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "Zip a folder of the following:\n",
    "1. Files that you were provided with: `Project-1.ipynb`, the folders `misc` and `dataset`. Rest of the files asked in the questions below must be generated when i run the code. If generation of any file is computationally intensive, add `filename_backup.extension` where `filename.extension` is the expected name of file when i run the code. (For example, next point.)\n",
    "2. Add `opt_backup.g2o` (described below) in outermost directory. Here, `opt.g2o` is the expected name of the file when I run the code.\n",
    "3. For images of any results (like plots), save it in `./misc` folder.\n",
    "\n",
    "On Moodle, all you have to submit is the jupyter notebook. But make sure to call the necessary functions explicitly (as specified in the notebook). The name of the zipped file being submitted to Moodle Assignment portal MUST BE `ID_Teamname_Firstname`. More details [here](https://www.notion.so/saishubodh/Course-Information-4c9e487b118547b2ba91d24e0dcaf04e#f2707a04f2a0446bac77763b47ba4bac).\n",
    "\n",
    "On GitHub classrooms, the latest commit before the deadline will be considered as the submission. \n",
    "\n",
    "The deadline is Oct 16, 23:55 IST. Please get started ASAP, there is no way you can finish this project during the last few days before the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General instructions\n",
    "\n",
    "This ipython notebook (`.ipynb`) on GitHub is self-sufficient and has all the information you need to get started with the assignment, you don't need any corresponding PDF doc. Just fire up the notebook and get going!\n",
    "\n",
    "General information like installation instructions in supplementary notebook \"Project-1_Code-Walkthrough\". Please take a look at it before you start this assignment.\n",
    "\n",
    "Whenever I mention some `func()` below, I am referring to the \"helper functions\" in another supplementary notebook \"Project-1_Code-Walkthrough\" provided to you. Whenever I ask you to insert image below, it is better to save the image in `misc` and load it using `![file_name](file_location)` instead of directly pasting.    \n",
    "\n",
    "[[CP-]] refers to CheckPoint, you have to ensure you do the tasks at each of the [[CP-]] places below. Not ensuring [[CP-B]] (CheckPoint-Basic) will incur heavy penalty and potentially 0 for that sub-section, and [[CP-M]] (CheckPoint-Marks) has a particular mark weightage depending on your results at that particular CP.\n",
    "\n",
    "If you face any issues related to coding/installation, please raise an [issue here](https://github.com/Shubodh/MR-project1-pgo/issues). For any conceptual doubts, you can ask on Moodle or Teams as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "\n",
    "In this project, we are going to use a non-linear weighted least squares optimization approach to solve the problem of getting a better estimate of our robot's trajectory. Least squares formulations are widely used for optimization, be it computer vision or robotics or machine learning. We will dive deep into it during this project and you will have complete clarity on optimization for vector-valued residual functions. \n",
    "\n",
    "In this \"Introduction\" section, I am going to provide an introduction for SLAM problem for a robot operating in the 2D world. It is 2. section in this Project. The 1D SLAM problem (1.) is far much simpler to understand and will be described directly in the 1. section. \n",
    "\n",
    "In a 2D world, a robot has 3 degrees of freedom, i.e. its pose in the world can be expressed by the state vector $\\mathbf{x}=(x, y, \\theta)^{\\mathrm{T}}$. For the scope of this project, we are interested only in the robot's trajectory through the $2 \\mathrm{D}$ world, and NOT in distinct landmarks or the surronding map of the environment, i.e. we are only interested in \"L\"ocalization part of SLAM. \n",
    "\n",
    "Therefore, we can represent it as a graph where the vertices represent robot poses $\\mathbf{x}_{i}$ and edges represent the spatial constraints between these poses. Such a map is generally called a pose graph.\n",
    "\n",
    "Two different kinds of constraints are necessary for pose graph SLAM. The first are\n",
    "odometric constraints that connect two successive states $\\mathbf{x}_{i}$ and $\\mathbf{x}_{i+1}$ via a motion model. Furthermore, in order to perform loop closing, the robot has to recognize places it already visited before. This place recognition is also a part of the front-end and provides the second type of constraint, the loop closure constraints. These constraints connect two not necessarily successive poses $\\mathbf{x}_{i}$ and $\\mathbf{x}_{j}$.\n",
    "\n",
    "\n",
    "![SLAM-trajectory-lc.png](misc/SLAM-trajectory-lc.png)   ![SLAM-trajectory-robust.png](misc/SLAM-trajectory-robust.png) (Source: [Sunderhauf 2012](https://core.ac.uk/download/pdf/89299995.pdf))\n",
    "\n",
    "You will start from the inaccurate pose graph with odometry and loop closure information and by the end of this Project, you end up with an optimized pose graph (see above images) which should look close to ground truth trajectory. You can watch [this video](https://youtu.be/saVZtgPyyJQ) to get an intuition for what we're about to do.\n",
    "\n",
    "Okay, that's enough of theory. Let's get out hands dirty with the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import jax.numpy as jnp #see supplementary notebook to see how to use this\n",
    "from jax import jacfwd\n",
    "\n",
    "# If you're `importing numpy as np` for debugging purposes, \n",
    "# while submitting, please remove 'import numpy' and replace all np's with jnp's.(more in supplementary notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pose Graph Optimization for 1D SLAM\n",
    "\n",
    "A solved example for 1D SLAM which optimizes for pose variables using weighted least squares method (Gauss Newton) has been explained in the class. It has been made [available here](https://www.notion.so/saishubodh/Solved-Example-1D-SLAM-weighted-LS-Illustrating-Sparsity-in-SLAM-d8b45893843b4377b07b1d4aa1aab4de). Your first task is to code this from scratch. [[CP-M]]\n",
    "\n",
    "For this section, you have to calculate Jacobian analytically yourself and use it. However, you can check how correct `jax`'s `jacobian`. Its usage is explained in the supplementary notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Code for Section 1                                                   #\n",
    "pass\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pose Graph Optimization for 2D SLAM\n",
    "\n",
    "Things are about to get interesting!\n",
    "\n",
    "## 2.1 Coding from scratch\n",
    "\n",
    "### Objective\n",
    "A robot is travelling in a oval trajectory. It is equipped with wheel odometry for odometry information and RGBD sensors for loop closure information. Due to noise in wheel odometry it generates a noisy estimate of the trajectory. Our task is to use loop closure pairs to correct the drift.\n",
    "\n",
    "We pose this problem as a graph optimization problem. In our graph, poses are the vertices and constraints are the edges. \n",
    "\n",
    "### Given: \n",
    "In practical scenarios, we'd obtain the following from our sensors after some post-processing:\n",
    "1. Initial position\n",
    "2. Odometry Contraints/Edges: This \"edge\" information basically tells us relative transformation between two nodes. These two nodes are consecutive in the case of Odometry but not in the case of Loop Closure (next point).\n",
    "3. Loop Closure Contraints/Edges\n",
    "Remember that while optimizing, you have another kind of \"anchor\" edge as you've seen in 1. solved example.\n",
    "\n",
    "You have been given a text file named `edges.txt` which has all the above 3 and it follows G2O's format (as explained in class, [link here](https://www.notion.so/saishubodh/G2O-Edge-Description-fa07cc28967541dc8a71170de46c5da7) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details:\n",
    "1. Using the following motion model, you have to first generate the \"initialization\" for all the poses/vertices using the \"Given\" information. Just like in the 1D case.\n",
    "$$x_{k+1} = x_{k} + \\Delta x_{(k,k+1)} \\cos(\\theta_k) - \\Delta y_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "y_{k+1} = y_{k} + \\Delta y_{(k,k+1)} \\cos(\\theta_k) + \\Delta x_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "\\theta_{k+1} = \\theta_{k}+  \\Delta \\theta_{(k,k+1)} \\tag{3}$$\n",
    "\n",
    "Even the loop closure nodes are related by the above model, except that it need not necessarily be consecutive notes k and k+1.\n",
    "\n",
    "Save this initial trajectory as `edges-poses.g2o`.\n",
    "\n",
    "If you plot the initialized poses using odometry information, you need to get as the right plot [[CP-M]] below (this is the \"noisy trajectory\"): (Left one is the ground truth)\n",
    "![robot-poses-MR-P1.png](./misc/robot-poses-MR-P1.png)\n",
    "(Use `draw()` helper function or `g2o_viewer` or `EVO`)\n",
    "\n",
    "2. Now calculate the residual and the Jacobian and update your parameters using LM.\n",
    "\n",
    "Use LM algorithm. Regarding Jacobian calculation, you can use `jax`'s `jacobian` as part of your main code. However, you still have to separately calculate it analytically and verify if it matches with `jax`'s `jacobian` using [[CP-M]] frobenius norm `frobNorm()`). Calculation and verification is compulsory, but it is your choice to use whichever as part of your optimization. Use whichever is faster.\n",
    "\n",
    "3. Regarding LM iterations, stopping criterion, information matrix values.\n",
    "\n",
    "    1. [[CP-B]] As your iterations proceed, you have to print relevant information (iteration number and error value: [$F = \\frac{1}{2}  \\mathbf{f}^{\\top} \\mathbf{\\Omega} \\mathbf{f} $ (notion page link)](https://www.notion.so/saishubodh/From-linear-algebra-to-non-linear-weighted-least-squares-optimization-13cf17d318be4d45bb8577c4d3ea4a02#32832dee7d6c4ab49581463d9b784f21) at every step).\n",
    "    \n",
    "    2. [[CP-B]] You have to show the plots (ground truth, noisy & optimized: all 3 in a single plot) at every 10 steps or so.\n",
    "\n",
    "    3. [[CP-M]] You could start with information values of 500 for odom edges, 700 for loop closure edges, 1000 for anchor edge (same for all dimensions). However, you have to _heavily_ experiment with these values. (Given that you somehow know loop closure information is way more reliable than odometry.). At the end of your experimentation, your error $F = \\frac{1}{2}  \\mathbf{f}^{\\top} \\mathbf{\\Omega} \\mathbf{f} $ should by < 40. Explain your experimentation in detail using tables/plots etc if necessary.\n",
    "    \n",
    "Do not worry if you're not getting a perfect trajectory. Our parametrization was oversimplified for the sake of this project. With that being said, it is possible to get the error down to < 40 and make it at least look like an oval shaped trajectory, even if it doesn't perfectly resemble the ground truth. However, using `g2o` (next section), you will be getting a close to ground truth trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Code for Section 2.1                                                 #\n",
    "pass\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Answer\n",
    "\n",
    "Give a detailed answer addressing the above questions. When I run the above code, it should follow points described above (such as plots at every 10 steps) and (When I run the above code, it should) write the optimized poses to a file named `opt.g2o`. As a backup, save another file `opt_backup.g2o` in an offline manner beforehand.\n",
    "\n",
    "That apart, save important plots and add them here so that it can supplement your answer, for example you could add plots at crucial stages of optimization. You have to add useful metrics/plots from `EVO` (refer to supplementary notebook). Using EVO, the bare minimum you have to report is `mean absolute pose error (ape)` and `mean relative pose error (rpe)`. However, you are encouraged to use tools like `evo_traj` and [more](https://github.com/MichaelGrupp/evo/#command-line-interface) and add more plots/metrics. Marks will be awarded based on overall analysis & presentation which would reflect your understanding.\n",
    "\n",
    "Note that `EVO` and `g2o_viewer` (below) could help you in debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add answer for 2.1 here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Using g2o's optimization: g2o binary or g2o viewer \n",
    "\n",
    "Installation setup is described in supplementary notebook. More details for 2.2.1 and 2.2.2 can be found in the supplementary notebook.\n",
    "\n",
    "### 2.2.1 Optimizing `edges.txt`\n",
    "First task is to optimize the poses of dataset you've been working with so far.\n",
    "\n",
    "### 2.2.2 Optimizing `intel` and `sphere` datasets\n",
    "You have been given two datasets in the `data` folder. You have to use `g2o_viewer` to optimize these both. You have to experiment with the options/parameters available in the GUI. More instructions in supplementary notebook. You have to experiment till you get the trajectories which look like the following:\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"./misc/intel.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src=\"./misc/sphere.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Answer\n",
    "\n",
    "Add images: take screenshot of the GUI of `g2o_viewer` after optimization for all 3 [[CP-M]] and add here. Briefly describe what you had to do (detailed answer is not expected). g2o could potentially give you close to ground truth trajectory for all 3, but if you are unable to get to close to ground truth, add the best you can get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  * Important Information regarding Questions 3  & 4\n",
    "Note that it is mandatory to attempt EITHER 3 OR 4, only one of it. If you attempt both, the question which you score more will be considered and the other as bonus question. \n",
    "\n",
    "It is encouraged for those into robotics/deep learning research to prefer 4 over 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bonus*] 3. Deriving Motion model geometrically\n",
    "\\* -> read information above under section \"Important Information regarding Questions 3  & 4\"\n",
    "\n",
    " \n",
    "The current robot state is as follows: ($i$ and $k$ are interchangably used below, sorry I am too lazy to edit now 😛)  \n",
    "![robot-situation.png](./misc/robot-situation.png)\n",
    "\n",
    "Can you derive the below equation using geometry? (Read on)\n",
    "\n",
    "$$x_{k+1} = x_{k} + \\Delta x_{(k,k+1)} \\cos(\\theta_k) - \\Delta y_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "y_{k+1} = y_{k} + \\Delta y_{(k,k+1)} \\cos(\\theta_k) + \\Delta x_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "\\theta_{k+1} = \\theta_{k}+  \\Delta \\theta_{(k,k+1)} \\tag{3}$$\n",
    "\n",
    "In other words, we want to find $\\delta$'s in terms of $\\Delta$'s\n",
    "$$\\delta x = \\Delta x \\cos(\\theta) - \\Delta y \\sin(\\theta) \\\\\n",
    "\\delta y = \\Delta y \\cos(\\theta) + \\Delta x \\sin(\\theta) \\tag{2}$$\n",
    "\n",
    "where $\\delta$'s are the updates in our motion model equation:\n",
    "$$ x_{k+1} = x_{k} + \\delta x \\\\\n",
    "y_{k + 1} = y_k + \\delta y \\\\\n",
    "\\theta_{k+1} = \\theta_{k} + \\delta \\theta \\tag{1}$$\n",
    "\n",
    "Oh yes, $\\theta$ is straightforward, i.e. $\\delta \\theta = \\Delta \\theta$ but why? \n",
    "\n",
    "Using geometry, you could just draw and insert a self-explanatory image as the answer to this question.\n",
    "\n",
    "If you can derive it without using geometry purely using transform matrices/algebra, that is fine too. Whatever you're comfortable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Answer\n",
    "\n",
    "\n",
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bonus*] 4. Research Paper Reading\n",
    "\\* -> read information above under section \"Important Information regarding Questions 3  & 4\"\n",
    "\n",
    "(Do not get intimidated, you are not expected to do a thorough research analysis for this task. A high level understanding is sufficient.)\n",
    "\n",
    "\n",
    "[\"Past, Present & Future of SLAM: Towards the Robust Perception Age\"](https://arxiv.org/abs/1606.05830) is an exciting survey paper of 2016 which sums up, well, the \"past, present & future\" of SLAM. Your task is as follows:\n",
    "\n",
    "1. Go through the sections \"IV. LONG-TERM AUTONOMY II: SCALABILITY\" & \"III. LONG-TERM AUTONOMY I: ROBUSTNESS\". Don't worry, you are not expected to have a deep understanding. Skip the parts which you don't understand at all. Go through it at a high level, and take a slightly closer look at \"Open Problems\" in these sections.\n",
    "\n",
    "2. Read up common applications of deep learning for computer vision/robotics through blogs online (for example, first 4 points of [this](https://machinelearningmastery.com/applications-of-deep-learning-for-computer-vision/). Again, you are only expected to understand it at a high level, for example, 'semantic segmentation is an application of deep learning for computer vision which is the task of assigning a category to each of the pixels in the image'.\n",
    "\n",
    "Firstly, summarize your understanding of the above two points.\n",
    "   \n",
    "Now, from the understanding you've gathered so far, how would you approach solving those \"Open Problems\"? \n",
    "Can these algorithms help in dealing with some of the issues you might have faced during this project? Can the deep learing based high level understanding of the world help in SLAM? In the context of long term autonomy, imagine tomorrow's world with a buddy robot R2-D2 which follows you wherever you go... Now imagine how easily the trajectory can diverge, how big the map could soon become and how the computation could easily become intractable.   \n",
    "\n",
    "Answer the above questions in the context of this project and those 2 sections of the survey paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Answer\n",
    "\n",
    "\n",
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun section\n",
    "Check the end of your Project-1 homepage on Notion. :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
